<?xml version="1.0" encoding="UTF-8"?>
<workflow>
  <name>execute_sql</name>
  <name_sync_with_filename>Y</name_sync_with_filename>
  <description/>
  <extended_description/>
  <workflow_version/>
  <workflow_status>0</workflow_status>
  <created_user>-</created_user>
  <created_date>2021/12/06 11:06:55.486</created_date>
  <modified_user>-</modified_user>
  <modified_date>2021/12/06 11:06:55.486</modified_date>
  <parameters>
    <parameter>
      <name>PARAM_AWS_ENDPOINT</name>
      <default_value/>
      <description/>
    </parameter>
    <parameter>
      <name>PARAM_AWS_ID</name>
      <default_value/>
      <description/>
    </parameter>
    <parameter>
      <name>PARAM_AWS_IMPORT_ARG</name>
      <default_value/>
      <description/>
    </parameter>
    <parameter>
      <name>PARAM_AWS_KEY</name>
      <default_value/>
      <description/>
    </parameter>
    <parameter>
      <name>PARAM_AWS_S3_BUCKET</name>
      <default_value/>
      <description/>
    </parameter>
    <parameter>
      <name>PARAM_CSV_FILE_BATCH</name>
      <default_value/>
      <description/>
    </parameter>
    <parameter>
      <name>PARAM_IMPORT_CSV_FILENAME</name>
      <default_value/>
      <description/>
    </parameter>
    <parameter>
      <name>PARAM_SQL_FILENAME</name>
      <default_value/>
      <description/>
    </parameter>
  </parameters>
  <actions>
    <action>
      <name>Start</name>
      <description/>
      <type>SPECIAL</type>
      <attributes/>
      <repeat>N</repeat>
      <schedulerType>0</schedulerType>
      <intervalSeconds>0</intervalSeconds>
      <intervalMinutes>60</intervalMinutes>
      <hour>12</hour>
      <minutes>0</minutes>
      <weekDay>1</weekDay>
      <DayOfMonth>1</DayOfMonth>
      <parallel>N</parallel>
      <xloc>416</xloc>
      <yloc>176</yloc>
      <attributes_hac/>
    </action>
    <action>
      <name>IMPORT INTO</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>${PARAM_PROJECT_HOME}/sql/${PARAM_SQL_FILENAME}</sqlfilename>
      <sendOneStatement>T</sendOneStatement>
      <connection>crdb</connection>
      <parallel>N</parallel>
      <xloc>608</xloc>
      <yloc>176</yloc>
      <attributes_hac/>
    </action>
    <action>
      <name>Success</name>
      <description/>
      <type>SUCCESS</type>
      <attributes/>
      <parallel>N</parallel>
      <xloc>1040</xloc>
      <yloc>176</yloc>
      <attributes_hac/>
    </action>
    <action>
      <name>Write to log</name>
      <description/>
      <type>WRITE_TO_LOG</type>
      <attributes/>
      <logmessage/>
      <loglevel>Minimal</loglevel>
      <logsubject/>
      <parallel>N</parallel>
      <xloc>608</xloc>
      <yloc>288</yloc>
      <attributes_hac/>
    </action>
    <action>
      <name>Update batch PROCESSED</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>update queue set status='PROCESSED' where batch='${PARAM_BATCH_ID}';</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>crdb</connection>
      <parallel>N</parallel>
      <xloc>816</xloc>
      <yloc>176</yloc>
      <attributes_hac/>
    </action>
  </actions>
  <hops>
    <hop>
      <from>Start</from>
      <to>IMPORT INTO</to>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>IMPORT INTO</from>
      <to>Write to log</to>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>IMPORT INTO</from>
      <to>Update batch PROCESSED</to>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Update batch PROCESSED</from>
      <to>Success</to>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
  </hops>
  <notepads>
    <notepad>
      <note>Need to make this dynamic,
Read CSV, find fields, put in the IMPORT into statement.
Allow multiple files in IMPORT statement.</note>
      <xloc>416</xloc>
      <yloc>48</yloc>
      <width>349</width>
      <heigth>58</heigth>
      <fontname>.AppleSystemUIFont</fontname>
      <fontsize>13</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>14</fontcolorred>
      <fontcolorgreen>58</fontcolorgreen>
      <fontcolorblue>90</fontcolorblue>
      <backgroundcolorred>201</backgroundcolorred>
      <backgroundcolorgreen>232</backgroundcolorgreen>
      <backgroundcolorblue>251</backgroundcolorblue>
      <bordercolorred>14</bordercolorred>
      <bordercolorgreen>58</bordercolorgreen>
      <bordercolorblue>90</bordercolorblue>
    </notepad>
    <notepad>
      <note>TODO: gracefully handle
: checking for key collisions: ingested key collides with an existing one: /Table/116/1/"\x00\x00\x12X\xc3TB\a\xb7\x90T^3\x88\xc5\x03"/0

Then add option in config, ignore colliding keys
</note>
      <xloc>384</xloc>
      <yloc>400</yloc>
      <width>837</width>
      <heigth>90</heigth>
      <fontname>.AppleSystemUIFont</fontname>
      <fontsize>13</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>14</fontcolorred>
      <fontcolorgreen>58</fontcolorgreen>
      <fontcolorblue>90</fontcolorblue>
      <backgroundcolorred>201</backgroundcolorred>
      <backgroundcolorgreen>232</backgroundcolorgreen>
      <backgroundcolorblue>251</backgroundcolorblue>
      <bordercolorred>14</bordercolorred>
      <bordercolorgreen>58</bordercolorgreen>
      <bordercolorblue>90</bordercolorblue>
    </notepad>
  </notepads>
  <attributes/>
</workflow>
